{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook creates the SQL tables on the Heroku database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SQLAlchemy Dependencies \n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other dependencies\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import pandas_datareader as pdr\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what day it is\n",
    "today = dt.utcnow().date()\n",
    "today = dt.utcnow().date().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to gather and clean stock data and upload to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from single stock ticker\n",
    "def Get_Stock(ticker):\n",
    "    df = pdr.DataReader(ticker, data_source='yahoo', start='2019-01-01', end=today)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['Close'])\n",
    "    df = df.rename(columns={'Adj Close':'Adj_Close'})\n",
    "    df = df[pd.notnull(df['Adj_Close'])]\n",
    "    df.insert(6, column='Ticker', value=ticker)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To update database with dataframe \n",
    "def Update_Database(df_name, table_name):\n",
    "    engine = create_engine('postgres://enwwbrxgztksrt:1c2aad3ab81e0cf9607b24d641b4f4be8a34a9841e3cac37739b4ba14569b605@ec2-3-214-3-162.compute-1.amazonaws.com:5432/dfidnj18uan5ha', echo=False)\n",
    "    session = Session(engine)\n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)    \n",
    "    cxn = engine.connect()\n",
    "    df_name.to_sql(name=table_name, con=engine, if_exists='append', index=True)\n",
    "    print(table_name + ' added')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating stock dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create entertainment df\n",
    "gc = Get_Stock('GC.TO')\n",
    "recp = Get_Stock('RECP.TO')\n",
    "cgx = Get_Stock('CGX.TO')\n",
    "\n",
    "entertainment_df = pd.concat([gc, recp, cgx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create telecommunication df\n",
    "rci = Get_Stock('RCI-B.TO')\n",
    "bce = Get_Stock('BCE.TO')\n",
    "\n",
    "\n",
    "telecommunication_df = pd.concat([rci, bce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create technology df\n",
    "kxs = Get_Stock('KXS.TO')\n",
    "shop = Get_Stock('SHOP.TO')\n",
    "\n",
    "technology_df = pd.concat([kxs, shop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aviation df\n",
    "ac = Get_Stock('AC.TO')\n",
    "bbd = Get_Stock('BBD-B.TO')\n",
    "\n",
    "aviation_df = pd.concat([ac, bbd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertainment added\n"
     ]
    }
   ],
   "source": [
    "Update_Database(entertainment_df, 'entertainment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telecommunication added\n"
     ]
    }
   ],
   "source": [
    "Update_Database(telecommunication_df, 'telecommunication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technology added\n"
     ]
    }
   ],
   "source": [
    "Update_Database(technology_df, 'technology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aviation added\n"
     ]
    }
   ],
   "source": [
    "Update_Database(aviation_df, 'aviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to close connections\n",
    "cxn.close()\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a table of dates and events scraped from Global News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Beautiful Soup\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request to news site\n",
    "url='https://globalnews.ca/news/6859636/ontario-coronavirus-timeline/'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to convert date-time\n",
    "numbers = ['1','2','3','4','5','6','7','8','9','10','11','12']\n",
    "names = ['Jan.','Feb.','March','April','May','June','July','Aug.','Sept.','Oct.','Nov.','Dec.']\n",
    "\n",
    "month_dict = dict(zip(names,numbers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists to hold parsed data\n",
    "dates =[]\n",
    "news =[]\n",
    "\n",
    "# Parse data \n",
    "soup = bs(response.text, 'html.parser')\n",
    "paragraphs = soup.find_all('p')\n",
    "for p in paragraphs:\n",
    "    # Remove html tags\n",
    "    p = p.get_text()  \n",
    "    # Select only news items in the form date, event \n",
    "    t = p.startswith(('Jan.','Feb.','March','April','May','June','July','Aug.','Sept.','Oct.','Nov.','Dec.'))\n",
    "    if t == True:                  \n",
    "        p = str(p).split(':')\n",
    "        datestr = p[0].strip() \n",
    "        datestr = datestr.replace(', ',' ')\n",
    "        datel = datestr.split(' ') \n",
    "        for (k,v) in month_dict.items():\n",
    "            if(datel[0] == k):\n",
    "                datel[0] = v\n",
    "        date = \"-\".join(datel)\n",
    "        date = dt.strptime(date, '%m-%d-%Y')\n",
    "        event = p[1].strip() # remove leading whitespace\n",
    "        dates.append(date)\n",
    "        news.append(event)\n",
    "        \n",
    "#print(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date                                               News\n",
      "0 2020-01-25  The first presumptive case is reported in Onta...\n",
      "1 2020-01-31  Ontarioâ€™s third case of the new coronavirus is...\n",
      "2 2020-02-12  Ontario health officials clear the London woma...\n",
      "3 2020-02-26  Ontario announces a fifth diagnosis in the pro...\n",
      "4 2020-03-11  A 77-year-old Barrie man dies, becoming Ontari...\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary of news items\n",
    "data = {\n",
    "    'Date' : dates,\n",
    "    'News' : news\n",
    "}\n",
    "\n",
    "# Transform dictionary to dataframe\n",
    "dates_df = pd.DataFrame(data, columns = ['Date','News'])\n",
    "dates_df['Date'] = pd.to_datetime(dates_df['Date'])\n",
    "print(dates_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates table pushed\n"
     ]
    }
   ],
   "source": [
    "def Update_Dates():\n",
    "    engine = create_engine('postgres://enwwbrxgztksrt:1c2aad3ab81e0cf9607b24d641b4f4be8a34a9841e3cac37739b4ba14569b605@ec2-3-214-3-162.compute-1.amazonaws.com:5432/dfidnj18uan5ha', echo=False)\n",
    "    session = Session(engine)\n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "    dates_df.to_sql(name='dates_table', con=engine, if_exists='append', index=True)\n",
    "    print('dates table pushed')\n",
    "\n",
    "Update_Dates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
